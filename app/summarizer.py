"""
Text processing module using OpenRouter API for summarization and task extraction
Handles summary generation, task extraction, and text analysis with fallback support
"""
import logging
from typing import Dict, Any
from openrouter_client import create_chat_completion
from config import CHAT_MODEL, TEMPERATURE, MAX_TEXT_LENGTH, MAX_TOKENS

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TextProcessor:
    """Handles text processing using OpenAI GPT models"""
    
    def __init__(self):
        self.max_text_length = MAX_TEXT_LENGTH
        self.model = CHAT_MODEL
        self.temperature = TEMPERATURE
    
    def _truncate_text(self, text: str) -> str:
        """Truncate text if it exceeds maximum length"""
        if len(text) <= self.max_text_length:
            return text
        
        truncated = text[:self.max_text_length - 100]  # Leave space for truncation message
        return f"{truncated}\n\n[Ð¢Ð•ÐšÐ¡Ð¢ ÐžÐ‘Ð Ð•Ð—ÐÐ - Ð¡Ð›Ð˜Ð¨ÐšÐžÐœ Ð”Ð›Ð˜ÐÐÐ«Ð™]"
    
    async def _call_ai_api(self, prompt: str, system_message: str = None) -> Dict[str, Any]:
        """
        Make a call to OpenRouter API with fallback support
        
        Args:
            prompt: User prompt to send
            system_message: Optional system message
            
        Returns:
            Dictionary with response or error
        """
        try:
            messages = []
            
            if system_message:
                messages.append({"role": "system", "content": system_message})
            
            messages.append({"role": "user", "content": prompt})
            
            # Call OpenRouter API with fallback
            response = await create_chat_completion(
                messages=messages,
                model=self.model,
                temperature=self.temperature,
                max_tokens=MAX_TOKENS
            )
            
            if response["success"]:
                return {
                    "success": True,
                    "content": response["content"],
                    "model": response.get("model", self.model),
                    "provider": response.get("provider", "unknown"),
                    "tokens_used": response.get("tokens_used", 0),
                    "input_tokens": response.get("input_tokens", 0),
                    "output_tokens": response.get("output_tokens", 0)
                }
            else:
                return {
                    "success": False,
                    "error": response.get("error", "Unknown API error"),
                    "content": "",
                    "provider": response.get("provider", "unknown")
                }
            
        except Exception as e:
            logger.error(f"AI API call failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "content": "",
                "provider": "unknown"
            }
    
    async def generate_summary_by_roles(self, text: str) -> Dict[str, Any]:
        """
        Generate a summary of the text organized by speakers/roles
        
        Args:
            text: Transcribed text with speaker markers
            
        Returns:
            Dictionary with summary results
        """
        truncated_text = self._truncate_text(text)
        
        system_message = """Ð¢Ñ‹ â€” Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹. 
Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ðµ, ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÑÐ²Ð¾Ð´ÐºÐ¸."""
        
        prompt = f"""Ð’Ð¾Ñ‚ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ñ Ð¼Ð°Ñ€ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð¸Ñ…:

{truncated_text}

Ð¡Ð¾Ð·Ð´Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÑƒÑŽ ÐžÐ‘Ð©Ð£Ð® Ð¡Ð’ÐžÐ”ÐšÐ£, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:
1. ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¸ Ñ‚ÐµÐ¼Ñ‹ Ð¾Ð±ÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ
2. ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ñ‘Ð½Ð½Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ
3. Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð²Ñ‹Ð²Ð¾Ð´Ñ‹
4. Ð’ÐºÐ»Ð°Ð´ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰ÐµÐ³Ð¾

ÐžÑ€Ð³Ð°Ð½Ð¸Ð·ÑƒÐ¹ ÑÐ²Ð¾Ð´ÐºÑƒ Ð¿Ð¾ Ñ€Ð¾Ð»ÑÐ¼/Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð¸Ð¼, ÐµÑÐ»Ð¸ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð².
Ð‘ÑƒÐ´ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¼, Ð½Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¼. ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 300 ÑÐ»Ð¾Ð²."""
        
        logger.info(f"Generating summary for text of {len(text)} characters")
        
        result = await self._call_openai(prompt, system_message)
        
        if result["success"]:
            logger.info("Summary generated successfully")
        
        return result
    
    async def extract_tasks(self, text: str) -> Dict[str, Any]:
        """
        Extract tasks and action items from the text
        
        Args:
            text: Transcribed text with speaker markers
            
        Returns:
            Dictionary with extracted tasks
        """
        truncated_text = self._truncate_text(text)
        
        system_message = """Ð¢Ñ‹ â€” Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡ Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°. 
Ð¢Ñ‹ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ, Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ð¼Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸."""
        
        prompt = f"""Ð’Ð¾Ñ‚ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ:

{truncated_text}

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ð’Ð¡Ð• Ð—ÐÐ”ÐÐ§Ð˜ Ð˜ Ð”Ð•Ð™Ð¡Ð¢Ð’Ð˜Ð¯, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½ÑƒÐ¶Ð½Ð¾ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:

Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:
ðŸ“‹ **Ð—ÐÐ”ÐÐ§Ð˜ Ð˜ Ð”Ð•Ð™Ð¡Ð¢Ð’Ð˜Ð¯:**

â€¢ **[Ð˜ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒ]** - ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
â€¢ **[Ð˜ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒ]** - ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
...

Ð•ÑÐ»Ð¸ Ð¸ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½ ÑÐ²Ð½Ð¾, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ **[ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½]**.
Ð•ÑÐ»Ð¸ Ð·Ð°Ð´Ð°Ñ‡ Ð½ÐµÑ‚, Ð½Ð°Ð¿Ð¸ÑˆÐ¸: "âŒ ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ Ð½Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾."

Ð˜Ñ‰Ð¸:
- ÐŸÑ€ÑÐ¼Ñ‹Ðµ Ð¿Ð¾Ñ€ÑƒÑ‡ÐµÐ½Ð¸Ñ ("ÑÐ´ÐµÐ»Ð°Ð¹", "Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÑŒ", "Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ")
- ÐžÐ±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð° ("Ñ ÑÐ´ÐµÐ»Ð°ÑŽ", "Ð¼Ð½Ðµ Ð½ÑƒÐ¶Ð½Ð¾")
- ÐŸÐ»Ð°Ð½Ñ‹ ("Ð½ÑƒÐ¶Ð½Ð¾", "Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾", "ÑÐ»ÐµÐ´ÑƒÐµÑ‚")
- Ð”ÐµÐ´Ð»Ð°Ð¹Ð½Ñ‹ Ð¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ€Ð°Ð¼ÐºÐ¸"""
        
        logger.info(f"Extracting tasks from text of {len(text)} characters")
        
        result = await self._call_openai(prompt, system_message)
        
        if result["success"]:
            logger.info("Tasks extracted successfully")
        
        return result
    
    async def format_full_text(self, text: str) -> Dict[str, Any]:
        """
        Format the full transcribed text for better readability
        
        Args:
            text: Transcribed text with speaker markers
            
        Returns:
            Dictionary with formatted text
        """
        try:
            # Simple formatting - add headers and clean up
            formatted_text = f"""ðŸ“ **ÐŸÐžÐ›ÐÐÐ¯ Ð¢Ð ÐÐÐ¡ÐšÐ Ð˜ÐŸÐ¦Ð˜Ð¯**

{text}

---
ðŸ’¡ *Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ AI. Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹ Ð½ÐµÑ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸.*"""
            
            return {
                "success": True,
                "content": formatted_text,
                "original_length": len(text),
                "formatted_length": len(formatted_text)
            }
            
        except Exception as e:
            logger.error(f"Text formatting failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "content": text
            }
    
    def get_text_stats(self, text: str) -> Dict[str, Any]:
        """
        Get statistics about the text
        
        Args:
            text: Input text
            
        Returns:
            Dictionary with text statistics
        """
        words = text.split()
        lines = text.split('\n')
        
        return {
            "characters": len(text),
            "words": len(words),
            "lines": len(lines),
            "within_limits": len(text) <= self.max_text_length,
            "speakers_detected": text.count("**Ð“Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð¸Ð¹"),
            "estimated_reading_time": max(1, len(words) // 200)  # ~200 words per minute
        }

# Global processor instance
processor = TextProcessor()

# Convenience functions
async def generate_summary(text: str) -> Dict[str, Any]:
    """Generate summary by roles"""
    return await processor.generate_summary_by_roles(text)

async def extract_action_items(text: str) -> Dict[str, Any]:
    """Extract tasks and action items"""
    return await processor.extract_tasks(text)

async def format_transcript(text: str) -> Dict[str, Any]:
    """Format full transcript"""
    return await processor.format_full_text(text)
